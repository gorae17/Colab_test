{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0414.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorae17/Colab_test/blob/master/0414.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hdSPG4oHzy5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "43e4188e-485c-4e23-ee33-59c73c5443c8"
      },
      "cell_type": "code",
      "source": [
        "# 삭제\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ls /gdrive/My\\ Drive/Colab\\ Notebooks/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            " 캐글스터디\t      '0412.ipynb의 사본'       AClassification.train.txt\n",
            " 04122.ipynb\t      '0412.ipynb의 사본 (1)'   models\n",
            "'04122.ipynb의 사본'   0413.ipynb\t        MultiLabelClassification.ipynb\n",
            " 0412.ipynb\t       0414.ipynb\t        Untitled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZZvfMLrq0Eg3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import fbeta_score\n",
        "#from sklearn.metrics import accuracy_score\n",
        "\n",
        "Ep = sys.float_info.epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8hKfBUY0EpS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def final_predict(x):\n",
        "  re = [0 for i in range(0,len(x))]\n",
        "  arg = np.array(x).argsort()\n",
        "  re[arg[-1]] = 1\n",
        "  for idx in arg[-3:-1]:\n",
        "    if x[idx] < 0.6:\n",
        "      re[idx] = 0\n",
        "    else:\n",
        "      re[idx] = 1\n",
        "  return re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9zH3kys0Enr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = open('/gdrive/My Drive/Colab Notebooks/AClassification.train.txt','r').readlines()\n",
        "data = [line.strip().split('\\t') for line in data]\n",
        "df = pd.DataFrame.from_records(data, columns=['id','labels','features'])\n",
        "df['features'] = df['features'].apply(lambda x: \" \".join([tok.split('/')[0] for tok in x.split(' ')[:300]]))\n",
        "df['labels'] = df['labels'].apply(lambda x: [int(y) for y in x.split()])\n",
        "categories = list(range(0, 20))\n",
        "for i in categories:\n",
        "  df[i] = df['labels'].apply(lambda x: 1 if i in x else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H-K_lfzk1aNt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, random_state=17, test_size=0.3, shuffle=True)\n",
        "x_train = train.features\n",
        "x_test = test.features\n",
        "trainedmodel = {}\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(x_train)\n",
        "x_train_v = vectorizer.transform(x_train)\n",
        "x_test_v = vectorizer.transform(x_test)                             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PZUEGoCxIMKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1017
        },
        "outputId": "bd986161-1f35-4504-ca00-32b49e5467a8"
      },
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "for category in categories:\n",
        "\n",
        "  print('... Processing {}'.format(category))\n",
        "  \n",
        "  lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, \n",
        "                           subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
        "\n",
        "  lgbm_reg.fit(x_train_v, train[category])\n",
        "  trainedmodel['LGBM{}'.format(category)] = lgbm_reg\n",
        "  \n",
        "  test['p{}'.format(category)] = np.array(lgbm_reg.predict(x_test_v))\n",
        "\n",
        "col = ['id','labels','features'] + ['p{}'.format(x) for x in range(0,20)]\n",
        "y_test = test.drop(columns=col)\n",
        "col = ['id','labels','features'] + list(range(0,20))\n",
        "y_pred = test.drop(columns=col)\n",
        "#y_pred = np.array([res for res in y_pred.apply(lambda x: final_predict(x), axis=1)])\n",
        "\n",
        "print('f0.5 score {}'.format(fbeta_score(np.array(y_test),np.array(y_pred),0.5,average='micro')))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... Processing 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Processing 1\n",
            "... Processing 2\n",
            "... Processing 3\n",
            "... Processing 4\n",
            "... Processing 5\n",
            "... Processing 6\n",
            "... Processing 7\n",
            "... Processing 8\n",
            "... Processing 9\n",
            "... Processing 10\n",
            "... Processing 11\n",
            "... Processing 12\n",
            "... Processing 13\n",
            "... Processing 14\n",
            "... Processing 15\n",
            "... Processing 16\n",
            "... Processing 17\n",
            "... Processing 18\n",
            "... Processing 19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-14c818a480ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#y_pred = np.array([res for res in y_pred.apply(lambda x: final_predict(x), axis=1)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f0.5 score {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m    832\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "dkKZb3cvcIgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "efc49639-265f-4e3d-e9ab-9aa8455fcb60"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "for category in categories:\n",
        "  test['p{}'.format(category)] = [0 if abs(1-x) > abs(x) else 1 for x in np.array(trainedmodel['LGBM{}'.format(category)].predict(x_test_v))]\n",
        "\n",
        "col = ['id','labels','features'] + list(range(0,20))\n",
        "y_pred = test.drop(columns=col)\n",
        "#y_pred = np.array([res for res in y_pred.apply(lambda x: final_predict(x), axis=1)])\n",
        "\n",
        "print('f0.5 score {}'.format(fbeta_score(np.array(y_test),np.array(y_pred),0.5,average='micro')))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "f0.5 score 0.8681464873639997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kP7G0RyTclfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "9be7112f-37d1-4690-e7b3-9c2dafaad8d5"
      },
      "cell_type": "code",
      "source": [
        "y_pred.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p0</th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "      <th>p3</th>\n",
              "      <th>p4</th>\n",
              "      <th>p5</th>\n",
              "      <th>p6</th>\n",
              "      <th>p7</th>\n",
              "      <th>p8</th>\n",
              "      <th>p9</th>\n",
              "      <th>p10</th>\n",
              "      <th>p11</th>\n",
              "      <th>p12</th>\n",
              "      <th>p13</th>\n",
              "      <th>p14</th>\n",
              "      <th>p15</th>\n",
              "      <th>p16</th>\n",
              "      <th>p17</th>\n",
              "      <th>p18</th>\n",
              "      <th>p19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>242364</th>\n",
              "      <td>0.002795</td>\n",
              "      <td>0.007837</td>\n",
              "      <td>0.004527</td>\n",
              "      <td>0.000752</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.580224</td>\n",
              "      <td>-0.011297</td>\n",
              "      <td>0.005742</td>\n",
              "      <td>0.017047</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.029697</td>\n",
              "      <td>0.004576</td>\n",
              "      <td>0.016042</td>\n",
              "      <td>0.002455</td>\n",
              "      <td>-0.040028</td>\n",
              "      <td>0.034978</td>\n",
              "      <td>-0.000074</td>\n",
              "      <td>-0.001914</td>\n",
              "      <td>0.201407</td>\n",
              "      <td>0.000957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70377</th>\n",
              "      <td>0.009881</td>\n",
              "      <td>0.014179</td>\n",
              "      <td>0.004539</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>0.000919</td>\n",
              "      <td>0.066988</td>\n",
              "      <td>0.001322</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>0.016006</td>\n",
              "      <td>0.001137</td>\n",
              "      <td>0.011614</td>\n",
              "      <td>0.877641</td>\n",
              "      <td>0.024530</td>\n",
              "      <td>0.002455</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>0.004064</td>\n",
              "      <td>0.018970</td>\n",
              "      <td>-0.000211</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124907</th>\n",
              "      <td>0.000102</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>-0.000049</td>\n",
              "      <td>0.000752</td>\n",
              "      <td>0.001776</td>\n",
              "      <td>-0.000216</td>\n",
              "      <td>0.414224</td>\n",
              "      <td>-0.000091</td>\n",
              "      <td>0.001161</td>\n",
              "      <td>-0.000058</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>-0.003584</td>\n",
              "      <td>0.085750</td>\n",
              "      <td>0.137093</td>\n",
              "      <td>-0.004562</td>\n",
              "      <td>-0.000074</td>\n",
              "      <td>-0.000211</td>\n",
              "      <td>0.475436</td>\n",
              "      <td>-0.000111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280141</th>\n",
              "      <td>0.009881</td>\n",
              "      <td>0.014179</td>\n",
              "      <td>0.016790</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>0.003887</td>\n",
              "      <td>0.764771</td>\n",
              "      <td>0.001322</td>\n",
              "      <td>0.011438</td>\n",
              "      <td>0.026647</td>\n",
              "      <td>0.000397</td>\n",
              "      <td>0.019147</td>\n",
              "      <td>0.014426</td>\n",
              "      <td>0.022165</td>\n",
              "      <td>0.002455</td>\n",
              "      <td>0.000253</td>\n",
              "      <td>0.003760</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>-0.000211</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126377</th>\n",
              "      <td>0.003930</td>\n",
              "      <td>0.007385</td>\n",
              "      <td>0.006211</td>\n",
              "      <td>0.002853</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>0.023087</td>\n",
              "      <td>1.103708</td>\n",
              "      <td>0.006302</td>\n",
              "      <td>0.010122</td>\n",
              "      <td>-0.003037</td>\n",
              "      <td>0.008553</td>\n",
              "      <td>0.006302</td>\n",
              "      <td>0.207928</td>\n",
              "      <td>0.003230</td>\n",
              "      <td>0.089546</td>\n",
              "      <td>-0.002521</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>-0.000211</td>\n",
              "      <td>1.030747</td>\n",
              "      <td>0.003657</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              p0        p1        p2        p3        p4        p5        p6  \\\n",
              "242364  0.002795  0.007837  0.004527  0.000752  0.002930  0.580224 -0.011297   \n",
              "70377   0.009881  0.014179  0.004539  0.002853  0.000919  0.066988  0.001322   \n",
              "124907  0.000102  0.001700 -0.000049  0.000752  0.001776 -0.000216  0.414224   \n",
              "280141  0.009881  0.014179  0.016790  0.002853  0.003887  0.764771  0.001322   \n",
              "126377  0.003930  0.007385  0.006211  0.002853  0.002500  0.023087  1.103708   \n",
              "\n",
              "              p7        p8        p9       p10       p11       p12       p13  \\\n",
              "242364  0.005742  0.017047  0.000142  0.029697  0.004576  0.016042  0.002455   \n",
              "70377   0.011064  0.016006  0.001137  0.011614  0.877641  0.024530  0.002455   \n",
              "124907 -0.000091  0.001161 -0.000058  0.000459  0.000085 -0.003584  0.085750   \n",
              "280141  0.011438  0.026647  0.000397  0.019147  0.014426  0.022165  0.002455   \n",
              "126377  0.006302  0.010122 -0.003037  0.008553  0.006302  0.207928  0.003230   \n",
              "\n",
              "             p14       p15       p16       p17       p18       p19  \n",
              "242364 -0.040028  0.034978 -0.000074 -0.001914  0.201407  0.000957  \n",
              "70377   0.000253  0.004064  0.018970 -0.000211  0.000038  0.000957  \n",
              "124907  0.137093 -0.004562 -0.000074 -0.000211  0.475436 -0.000111  \n",
              "280141  0.000253  0.003760  0.000132 -0.000211  0.000038  0.000957  \n",
              "126377  0.089546 -0.002521  0.000132 -0.000211  1.030747  0.003657  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "xJV0sz9s0Ejx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "84641bb1-1074-43e7-e977-267c8b1e84a7"
      },
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "for category in categories:\n",
        "\n",
        "  print('... Processing {}'.format(category))\n",
        "  \n",
        "  lgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, \n",
        "                           subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\n",
        "\n",
        "  lgbm_reg.fit(x_train_v, train[category])\n",
        "  trainedmodel['LGBM{}'.format(category)] = lgbm_reg\n",
        "  \n",
        "  test['p{}'.format(category)] = np.array(lgbm_reg.predict(x_test_v))\n",
        "\n",
        "col = ['id','labels','features'] + ['p{}'.format(x) for x in range(0,20)]\n",
        "y_test = test.drop(columns=col)\n",
        "col = ['id','labels','features'] + list(range(0,20))\n",
        "y_pred = test.drop(columns=col)\n",
        "y_pred = np.array([res for res in y_pred.apply(lambda x: final_predict(x), axis=1)])\n",
        "\n",
        "print('f0.5 score {}'.format(fbeta_score(np.array(y_test),np.array(y_pred),0.5,average='micro')))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... Processing 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... Processing 1\n",
            "... Processing 2\n",
            "... Processing 3\n",
            "... Processing 4\n",
            "... Processing 5\n",
            "... Processing 6\n",
            "... Processing 7\n",
            "... Processing 8\n",
            "... Processing 9\n",
            "... Processing 10\n",
            "... Processing 11\n",
            "... Processing 12\n",
            "... Processing 13\n",
            "... Processing 14\n",
            "... Processing 15\n",
            "... Processing 16\n",
            "... Processing 17\n",
            "... Processing 18\n",
            "... Processing 19\n",
            "f0.5 score 0.8626659211861424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ucLsSq6Bz9qi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlZ604GmCMc-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN with Keras"
      ]
    },
    {
      "metadata": {
        "id": "p-YpaJztIeDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "dfda3b9d-7087-4d76-a966-f53c3e4fac34"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.backend import tensorflow_backend as K\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "K.set_session(tf.Session(config=config))\n",
        "\n",
        "# config = tf.ConfigProto()\n",
        "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
        "# K.set_session(tf.Session(config=config))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c42674f46d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_process_gpu_memory_fraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# config = tf.ConfigProto()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    674\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSessionRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: an illegal memory access was encountered"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1KGD_XjGHHHv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import fbeta_score\n",
        "#from sklearn.metrics import accuracy_score\n",
        "\n",
        "Ep = sys.float_info.epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9wF2NlP0HD_I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = open('/gdrive/My Drive/Colab Notebooks/AClassification.train.txt','r').readlines()\n",
        "data = [line.strip().split('\\t') for line in data]\n",
        "df = pd.DataFrame.from_records(data, columns=['id','labels','features'])\n",
        "df['features'] = df['features'].apply(lambda x: \" \".join([tok.split('/')[0] for tok in x.split(' ')[:300]]))\n",
        "df['labels'] = df['labels'].apply(lambda x: [int(y) for y in x.split()])\n",
        "categories = list(range(0, 20))\n",
        "for i in categories:\n",
        "  df[i] = df['labels'].apply(lambda x: 1 if i in x else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZqPfayMtKOw2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, random_state=17, test_size=0.3, shuffle=True)\n",
        "x_train = train.features\n",
        "x_test = test.features\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train) #5572개의 행을 가진 X의 각 행에 토큰화를 수행\n",
        "train_sequences = tokenizer.texts_to_sequences(x_train) #단어를 숫자값, 인덱스로 변환하여 저장\n",
        "test_sequences = tokenizer.texts_to_sequences(x_test) #단어를 숫자값, 인덱스로 변환하여 저장\n",
        "\n",
        "from keras.layers import SimpleRNN, Embedding, Dense, LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "max_features = 10000\n",
        "# feature로 사용할 단어의 수.\n",
        "maxlen = 300\n",
        "# e-mail에서 볼 최대 단어의 수는 500개\n",
        "\n",
        "train_data = pad_sequences(train_sequences, maxlen=maxlen)\n",
        "test_data = pad_sequences(test_sequences, maxlen=maxlen)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2xlFW7Caz9oc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1119
        },
        "outputId": "bdce0f2c-52b7-4a35-e49d-89333b5816a7"
      },
      "cell_type": "code",
      "source": [
        "for category in categories:\n",
        "  print('... Processing {}'.format(category))\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(max_features, 32))\n",
        "  model.add(SimpleRNN(32))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "  history = model.fit(train_data, train[category], epochs=10, batch_size=32, validation_split=0.2)\n",
        "  print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(test_data, test[category])[1]))\n",
        "  test['p{}'.format(category)] = model.predict(x_test)\n",
        "  \n",
        "col = ['id','labels','features'] + ['p{}'.format(x) for x in range(0,20)]\n",
        "y_test = test.drop(columns=col)\n",
        "col = ['id','labels','features'] + list(range(0,20))\n",
        "y_pred = test.drop(columns=col)\n",
        "#y_pred = np.array([res for res in y_pred.apply(lambda x: final_predict(x), axis=1)])\n",
        "\n",
        "print('f0.5 score {}'.format(fbeta_score(np.array(y_test),np.array(y_pred),0.5,average='micro')))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "... Processing 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 170340 samples, validate on 42586 samples\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InternalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-eec2c5a9ca2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n 테스트 정확도: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'p{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalError\u001b[0m: GPU sync failed"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "B9xs-nZlz9jI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}